![101 Innovations in Scholarly Communication](InnoScholComm_figure_jan2015_rising_sun_compressed.png)

# Discovering patterns in 20663 individual research workflows 
- using data from our recent [global survey on Innovations in Scholarly Communication] (http://101innovations.wordpress.com)
- this is a subbranch from master repo [101innovations-survey-data] (https://github.com/bmkramer/101innovations-survey-data)

## About

The results of our 2015-2016 survey on research tool usage can provide insights into current practices across various fields, research roles, countries and career stages, and can be useful for researchers interested in changing research workflows. 

Based on co-occurrences of tools/platforms in workflows, we aim to identify tool combinations that make up typical research workflows. 
Previously, we identified tool combinations (from the 119 preset tools/platforms in our survey) that are used together more or less often than expected by chance (for details see our blogpost [Tools that love to be together](https://101innovations.wordpress.com/2016/11/06/tools-that-love-to-be-together/)).

One of the possibilities to extend this analysis from separate tool combinations into groups of tools typifying full research workflows. Two of these possibilities are looking at clusters and cliques, respectively.

1. Clusters: tools occurring in similar workflows
Based on our co-occurrence data, we can look at which tools occur in similar workflows, i.e. have the most tools in common that they are or are not specifically used with. 

To facilitate collaboration on in-depth analysis, we made the data available as [open dataset on Kaggle] (https://www.kaggle.com/bmkramer/101-innovations-research-tools-survey) where scripts (in R, Python, Julia) can be written, executed and shared. Quick exploration of the survey results can be done in an [interactive dashboard on Silk] (http://dashboard101innovations.silk.co). The full raw and cleaned dataset of the survey (20,663 responses) is also available on [Zenodo] (http://dx.doi.org/10.5281/zenodo.49583), but we recommend downloading the data from Kaggle (see above).

## Mozilla Science Lab Global Sprint 2016 (June 2-3, 2016)
During the [Mozilla Science Lab Global Sprint
2016](https://www.mozillascience.org/global-sprint-2016), we made a start with these analyses by bringing together people with expertise in numerical and textual analysis. 

During the sprint, we used this etherpad to share thoughts, ideas, code snippets etc.: https://public.etherpad-mozilla.org/p/sprintutrecht

## ReCon Hackday (June 25, 2016)
During the [ReCon Hackday 2016](https://reconevent.com/hackday/), we hope to continue to work on these analyses with the help of smart people present, especially those with experience in e.g. R, Python, Google Refine, NVIVO or AtlasTI. Any and all ideas for analysis are welcome!

## Mozfest2016 (Oct 28-30, 2016)
During [Mozfest2016](https://mozillafestival.org/), we want to explore to which degree researchers can and do employ a full Open Science workflow. This [session](https://app.mozillafestival.org/#_session-338) will be both on statistical analysis of survey results and technical appraisal of Open Science tools and platforms. 

During Mozfest, we will use an [etherpad](https://public.etherpad-mozilla.org/p/mozfest-2016-real-life-open-science-workflows--use) to share thoughts, ideas and outcomes. We will also use a [specially created branch](https://github.com/bmkramer/101innovations-survey-data/tree/mozfest2016-Open-Science-workflows) of this repo. 

## Issue list
We added a [list of (broadly formulated) issues] (https://github.com/bmkramer/101innovations-survey-data/issues) to work on. Please add to them, add your comments and contribute where you can and want! 

## Further Information

- The project [Innovations in Scholarly Communication] (https://101innovations.wordpress.com/about-1/)
- The [survey dataset on Kaggle] (https://www.kaggle.com/bmkramer/101-innovations-research-tools-survey) where scripts can be written, executed and shared
